{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nilearn\n",
    "from nibabel.testing import data_path\n",
    "from nilearn import datasets, plotting, regions\n",
    "import brainspace\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from nilearn import surface\n",
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "#import hcp_utils as hcp\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import seaborn as sns\n",
    "from surfplot.plotting import Plot\n",
    "from icc_utils import *\n",
    "from hyppo.discrim import DiscrimOneSample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects = [\"100206\", \"100307\", \"100408\", \"100610\", \"101006\"]\n",
    "gradient_list = []\n",
    "for subject in subjects:\n",
    "    gradient = np.load(\"HCP/Gradients/%s/%s.pca.ses1.s02mm.npy\" % (subject, subject))\n",
    "    gradient_list.append(gradient.T)\n",
    "\n",
    "gradients_ses1 = np.stack((gradient_list))\n",
    "\n",
    "gradient_list = []\n",
    "for subject in subjects:\n",
    "    gradient = np.load(\"HCP/Gradients/%s/%s.pca.ses2.s02mm.npy\" % (subject, subject))\n",
    "    gradient_list.append(gradient.T)\n",
    "\n",
    "gradients_ses2 = np.stack((gradient_list))\n",
    "\n",
    "margulies_grads = np.load('margulies_grads_32K.npy').T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration   0: 1430372.139473\n",
      "Iteration   1: 0.002696\n",
      "Iteration   2: 0.000227\n",
      "Iteration   3: 0.000022\n",
      "Iteration   4: 0.000002\n",
      "Iteration   5: 0.000000\n",
      "Iteration   0: 1430444.230893\n",
      "Iteration   1: 0.001681\n",
      "Iteration   2: 0.000064\n",
      "Iteration   3: 0.000003\n",
      "Iteration   4: 0.000000\n"
     ]
    }
   ],
   "source": [
    "from brainspace.gradient.alignment import ProcrustesAlignment\n",
    "\n",
    "alignment = ProcrustesAlignment(verbose=True, n_iter = 10)\n",
    "allGradsAlignedObject_ses1 = alignment.fit(list(gradients_ses1), margulies_grads) # aligning to margulies 2016\n",
    "GradsAligned_ses1 = allGradsAlignedObject_ses1.aligned_\n",
    "allGradsAlignedObject_ses2 = alignment.fit(list(gradients_ses2), margulies_grads) # aligning to margulies 2016\n",
    "GradsAligned_ses2 = allGradsAlignedObject_ses2.aligned_\n",
    "\n",
    "np.save(arr = GradsAligned_ses1, file =\"Grads32kAligned2Margulies2016_ses1.npy\")\n",
    "np.save(arr = GradsAligned_ses2, file =\"Grads32kAligned2Margulies2016_ses2.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "aligned_grads_32k_ses1 = np.load(\"Grads32kAligned2Margulies2016_ses1.npy\")\n",
    "aligned_grads_32k_ses2 = np.load(\"Grads32kAligned2Margulies2016_ses2.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "disp_ses1 = []\n",
    "for i in range(len(aligned_grads_32k_ses1)):\n",
    "    disp_ses_1 = gradDispersion(aligned_grads_32k_ses1[i], 1600, save = True, filename = \"disp_1600neighbours_ses1.npy\")\n",
    "    disp_ses1.append(disp_ses_1)\n",
    "\n",
    "disp_ses2 = []\n",
    "for i in range(len(aligned_grads_32k_ses2)):\n",
    "    disp_ses_2 = gradDispersion(aligned_grads_32k_ses2[i], 1600, save = True, filename = \"disp_1600neighbours_ses2.npy\")\n",
    "    disp_ses2.append(disp_ses_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(arr = np.asarray(disp_ses1), file = \"dispersion_ses1.npy\")\n",
    "np.save(arr = np.asarray(disp_ses2), file = \"dispersion_ses2.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "disp_ses1 = np.load(\"dispersion_ses1.npy\")\n",
    "disp_ses2 = np.load(\"dispersion_ses2.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "disp_array = np.asarray([np.stack((i, j)) for i, j in zip(disp_ses1, disp_ses2)])\n",
    "disp_array = np.concatenate((disp_array, disp_array, disp_array))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15, 2, 59412)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(15, 2)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disp_array.shape\n",
    "disp_array.mean(axis = 2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.concatenate([np.zeros((50, 2)), np.ones((50, 2))], axis=0)\n",
    "y = np.concatenate([np.zeros(50), np.ones(50)], axis=0)\n",
    "#'%.1f, %.2f' % DiscrimOneSample().test(, y) \n",
    "#'1.0, 0.00'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 2)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(118824, 2)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape\n",
    "x = np.concatenate((x1, x2))\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DiscrimOneSampleTestOutput(stat=1.0, pvalue=0.000999000999000999)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DiscrimOneSample().test(disp_array.mean(axis = 2), np.asarray(subjects *3)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_subj_1 = [\"100206\"] * 59412\n",
    "label_subj_2 = [\"100201\"] * 59412\n",
    "label_subj = np.asarray(label_subj_1 + label_subj_2)\n",
    "label_vertex = np.arange(59412).astype(str)\n",
    "label_vertex = np.concatenate((label_vertex, label_vertex))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(118824,)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_vertex.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "disp = np.stack((disp_ses1, disp_ses2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = disp[:, 0, :].T\n",
    "x2 = disp[:, 1, :].T\n",
    "\n",
    "x = np.concatenate((x1, x2))\n",
    "y = np.stack((label_subj, label_vertex)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 237648)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.reshape(1, -1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[0.0007429  0.00118452 0.00161574 ... 0.00088336 0.0006237  0.00100984].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [105], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m DiscrimOneSample()\u001b[39m.\u001b[39;49mtest(x,y)\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/neuro/lib/python3.9/site-packages/hyppo/discrim/discrim_one_samp.py:120\u001b[0m, in \u001b[0;36mDiscrimOneSample.test\u001b[0;34m(self, x, y, reps, workers, random_state)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     77\u001b[0m \u001b[39mCalculates the test statistic and p-value for Discriminability one sample test.\u001b[39;00m\n\u001b[1;32m     78\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[39m'1.0, 0.00'\u001b[39;00m\n\u001b[1;32m    111\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    113\u001b[0m check_input \u001b[39m=\u001b[39m _CheckInputs(\n\u001b[1;32m    114\u001b[0m     [x],\n\u001b[1;32m    115\u001b[0m     y,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    118\u001b[0m     remove_isolates\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mremove_isolates,\n\u001b[1;32m    119\u001b[0m )\n\u001b[0;32m--> 120\u001b[0m x, y \u001b[39m=\u001b[39m check_input()\n\u001b[1;32m    122\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mx \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masarray(x[\u001b[39m0\u001b[39m])\n\u001b[1;32m    123\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39my \u001b[39m=\u001b[39m y\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/neuro/lib/python3.9/site-packages/hyppo/discrim/_utils.py:30\u001b[0m, in \u001b[0;36m_CheckInputs.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     28\u001b[0m     check_min_samples(x1)\n\u001b[1;32m     29\u001b[0m     x1, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39my \u001b[39m=\u001b[39m convert_xy_float64(x1, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39my)\n\u001b[0;32m---> 30\u001b[0m     tmp_\u001b[39m.\u001b[39mappend(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_condition_input(x1))\n\u001b[1;32m     32\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mx \u001b[39m=\u001b[39m tmp_\n\u001b[1;32m     34\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreps:\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/neuro/lib/python3.9/site-packages/hyppo/discrim/_utils.py:59\u001b[0m, in \u001b[0;36m_CheckInputs._condition_input\u001b[0;34m(self, x1)\u001b[0m\n\u001b[1;32m     56\u001b[0m         x1 \u001b[39m=\u001b[39m x1[np\u001b[39m.\u001b[39mix_(idx, idx)]\n\u001b[1;32m     58\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mis_distance:\n\u001b[0;32m---> 59\u001b[0m     x1 \u001b[39m=\u001b[39m pairwise_distances(x1, metric\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39meuclidean\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m     61\u001b[0m \u001b[39mreturn\u001b[39;00m x1\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/neuro/lib/python3.9/site-packages/sklearn/metrics/pairwise.py:2022\u001b[0m, in \u001b[0;36mpairwise_distances\u001b[0;34m(X, Y, metric, n_jobs, force_all_finite, **kwds)\u001b[0m\n\u001b[1;32m   2019\u001b[0m         \u001b[39mreturn\u001b[39;00m distance\u001b[39m.\u001b[39msquareform(distance\u001b[39m.\u001b[39mpdist(X, metric\u001b[39m=\u001b[39mmetric, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds))\n\u001b[1;32m   2020\u001b[0m     func \u001b[39m=\u001b[39m partial(distance\u001b[39m.\u001b[39mcdist, metric\u001b[39m=\u001b[39mmetric, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m-> 2022\u001b[0m \u001b[39mreturn\u001b[39;00m _parallel_pairwise(X, Y, func, n_jobs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/neuro/lib/python3.9/site-packages/sklearn/metrics/pairwise.py:1563\u001b[0m, in \u001b[0;36m_parallel_pairwise\u001b[0;34m(X, Y, func, n_jobs, **kwds)\u001b[0m\n\u001b[1;32m   1560\u001b[0m X, Y, dtype \u001b[39m=\u001b[39m _return_float_dtype(X, Y)\n\u001b[1;32m   1562\u001b[0m \u001b[39mif\u001b[39;00m effective_n_jobs(n_jobs) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m-> 1563\u001b[0m     \u001b[39mreturn\u001b[39;00m func(X, Y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m   1565\u001b[0m \u001b[39m# enforce a threading backend to prevent data communication overhead\u001b[39;00m\n\u001b[1;32m   1566\u001b[0m fd \u001b[39m=\u001b[39m delayed(_dist_wrapper)\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/neuro/lib/python3.9/site-packages/sklearn/metrics/pairwise.py:300\u001b[0m, in \u001b[0;36meuclidean_distances\u001b[0;34m(X, Y, Y_norm_squared, squared, X_norm_squared)\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39meuclidean_distances\u001b[39m(\n\u001b[1;32m    225\u001b[0m     X, Y\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m, Y_norm_squared\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, squared\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, X_norm_squared\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m\n\u001b[1;32m    226\u001b[0m ):\n\u001b[1;32m    227\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    228\u001b[0m \u001b[39m    Compute the distance matrix between each pair from a vector array X and Y.\u001b[39;00m\n\u001b[1;32m    229\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    298\u001b[0m \u001b[39m           [1.41421356]])\u001b[39;00m\n\u001b[1;32m    299\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 300\u001b[0m     X, Y \u001b[39m=\u001b[39m check_pairwise_arrays(X, Y)\n\u001b[1;32m    302\u001b[0m     \u001b[39mif\u001b[39;00m X_norm_squared \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    303\u001b[0m         X_norm_squared \u001b[39m=\u001b[39m check_array(X_norm_squared, ensure_2d\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/neuro/lib/python3.9/site-packages/sklearn/metrics/pairwise.py:146\u001b[0m, in \u001b[0;36mcheck_pairwise_arrays\u001b[0;34m(X, Y, precomputed, dtype, accept_sparse, force_all_finite, copy)\u001b[0m\n\u001b[1;32m    143\u001b[0m     dtype \u001b[39m=\u001b[39m dtype_float\n\u001b[1;32m    145\u001b[0m \u001b[39mif\u001b[39;00m Y \u001b[39mis\u001b[39;00m X \u001b[39mor\u001b[39;00m Y \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 146\u001b[0m     X \u001b[39m=\u001b[39m Y \u001b[39m=\u001b[39m check_array(\n\u001b[1;32m    147\u001b[0m         X,\n\u001b[1;32m    148\u001b[0m         accept_sparse\u001b[39m=\u001b[39;49maccept_sparse,\n\u001b[1;32m    149\u001b[0m         dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[1;32m    150\u001b[0m         copy\u001b[39m=\u001b[39;49mcopy,\n\u001b[1;32m    151\u001b[0m         force_all_finite\u001b[39m=\u001b[39;49mforce_all_finite,\n\u001b[1;32m    152\u001b[0m         estimator\u001b[39m=\u001b[39;49mestimator,\n\u001b[1;32m    153\u001b[0m     )\n\u001b[1;32m    154\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m     X \u001b[39m=\u001b[39m check_array(\n\u001b[1;32m    156\u001b[0m         X,\n\u001b[1;32m    157\u001b[0m         accept_sparse\u001b[39m=\u001b[39maccept_sparse,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    161\u001b[0m         estimator\u001b[39m=\u001b[39mestimator,\n\u001b[1;32m    162\u001b[0m     )\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/neuro/lib/python3.9/site-packages/sklearn/utils/validation.py:879\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    877\u001b[0m     \u001b[39m# If input is 1D raise error\u001b[39;00m\n\u001b[1;32m    878\u001b[0m     \u001b[39mif\u001b[39;00m array\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m--> 879\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    880\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mExpected 2D array, got 1D array instead:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39marray=\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    881\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mReshape your data either using array.reshape(-1, 1) if \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    882\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39myour data has a single feature or array.reshape(1, -1) \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    883\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mif it contains a single sample.\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(array)\n\u001b[1;32m    884\u001b[0m         )\n\u001b[1;32m    886\u001b[0m \u001b[39mif\u001b[39;00m dtype_numeric \u001b[39mand\u001b[39;00m array\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mkind \u001b[39min\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mUSV\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    887\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    888\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mdtype=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mnumeric\u001b[39m\u001b[39m'\u001b[39m\u001b[39m is not compatible with arrays of bytes/strings.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    889\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mConvert your data to numeric values explicitly instead.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    890\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[0.0007429  0.00118452 0.00161574 ... 0.00088336 0.0006237  0.00100984].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "DiscrimOneSample().test(x,y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neuro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a46811f360801e2b10c5cb0e5e692288746a4ce011302d6efda50fd28a2ae2e3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
